{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPD0edDfhj0LwqLJF8uGYmT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ravurumadhuri/Automate-Data-Cleaning/blob/main/Automate_data_cleaning_using_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nMnzHdo_MUsY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def clean_dataframe(df: pd.DataFrame, verbose: bool = True) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "\n",
        "    # log helper\n",
        "    def log(msg):\n",
        "        if verbose:\n",
        "            print(f\"[INFO] {msg}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define a placeholder log function to avoid NameError if not imported/defined globally\n",
        "def log(msg):\n",
        "    print(f\"[INFO] {msg}\")\n",
        "\n",
        "# Create a dummy DataFrame for demonstration purposes within this cell\n",
        "data = {'Column One ': [1, 2, 3], 'Another Column': ['A', 'B', 'C']}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# 1. standardize column names\n",
        "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
        "log(\"Standardized column names.\")\n",
        "\n",
        "# Display the modified DataFrame to show the result\n",
        "print(\"DataFrame after column standardization:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbkQbqTGY49z",
        "outputId": "862a047b-852b-41cc-8956-0b58d3d36726"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Standardized column names.\n",
            "DataFrame after column standardization:\n",
            "   column_one another_column\n",
            "0           1              A\n",
            "1           2              B\n",
            "2           3              C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. remove exact duplicates\n",
        "dup_count = df.duplicated().sum()\n",
        "if dup_count > 0:\n",
        "    df.drop_duplicates(inplace=True)\n",
        "    log(f\"Removed {dup_count} duplicate rows.\")"
      ],
      "metadata": {
        "id": "h0AqmCxsZXvb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. trim and lowercase all string (object) values\n",
        "for col in df.select_dtypes(include='object'):\n",
        "    df[col] = df[col].astype(str).str.strip().str.lower()\n",
        "log(\"Standardized string columns (lowercase + trimmed).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEGMhO5ZZr4f",
        "outputId": "eae17892-35d1-4f54-a05d-f109f6a9ebfb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Standardized string columns (lowercase + trimmed).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. detect missing values (including blanks and placeholders)\n",
        "placeholder_values = ['n/a', 'na', '--', '-', 'none', 'null', '', 'nan']\n",
        "df.replace(placeholder_values, np.nan, inplace=True)\n",
        "null_report = df.isnull().sum()\n",
        "null_report = null_report[null_report > 0]\n",
        "if not null_report.empty:\n",
        "    log(f\"Missing values found in columns:\\n{null_report}\")"
      ],
      "metadata": {
        "id": "TF4DSBrOaGA9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. flag constant columns\n",
        "constant_cols = [col for col in df.columns if df[col].nunique() == 1]\n",
        "if constant_cols:\n",
        "    log(f\"Constant columns (consider removing): {constant_cols}\")"
      ],
      "metadata": {
        "id": "Oj1vL3GHaase"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. flag high cardinality categorical columns\n",
        "high_card_cols = [col for col in df.select_dtypes(include='object') if df[col].nunique() > 100]\n",
        "if high_card_cols:\n",
        "    log(f\"High-cardinality columns (consider encoding strategies): {high_card_cols}\")\n",
        "\n",
        "# 7. detect numeric outliers using IQR\n",
        "num_cols = df.select_dtypes(include=np.number).columns\n",
        "outlier_report = {}\n",
        "for col in num_cols:\n",
        "    q1, q3 = df[col].quantile([0.25, 0.75])\n",
        "    iqr = q3 - q1\n",
        "    lower = q1 - 1.5 * iqr\n",
        "    upper = q3 + 1.5 * iqr\n",
        "    outliers = df[(df[col] < lower) | (df[col] > upper)][col].count()\n",
        "    if outliers > 0:\n",
        "        outlier_report[col] = outliers\n",
        "if outlier_report:\n",
        "    log(f\"Potential numeric outliers detected:\\n{outlier_report}\")\n",
        "\n",
        "# 8. convert applicable columns to category\n",
        "for col in df.select_dtypes(include='object'):\n",
        "    n_unique = df[col].nunique()\n",
        "    if n_unique < len(df) * 0.05:\n",
        "        df[col] = df[col].astype('category')\n",
        "log(\"Converted suitable object columns to category dtype.\")\n",
        "\n",
        "log(\"Data cleaning complete.\")\n",
        "# return df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQnr35vtaskp",
        "outputId": "6a5e1ee8-2032-4d83-81e7-b2de9049c0f6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Converted suitable object columns to category dtype.\n",
            "[INFO] Data cleaning complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def log(msg):\n",
        "    print(f\"[INFO] {msg}\")\n",
        "\n",
        "df = pd.read_csv('/content/loan-recovery.csv')\n",
        "\n",
        "# Apply cleaning steps directly to df\n",
        "# 1. standardize column names\n",
        "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
        "log(\"Standardized column names.\")\n",
        "\n",
        "# 2. remove exact duplicates\n",
        "dup_count = df.duplicated().sum()\n",
        "if dup_count > 0:\n",
        "    df.drop_duplicates(inplace=True)\n",
        "    log(f\"Removed {dup_count} duplicate rows.\")\n",
        "\n",
        "# 3. trim and lowercase all string (object) values\n",
        "for col in df.select_dtypes(include='object'):\n",
        "    df[col] = df[col].astype(str).str.strip().str.lower()\n",
        "log(\"Standardized string columns (lowercase + trimmed).\")\n",
        "\n",
        "# 4. detect missing values (including blanks and placeholders)\n",
        "placeholder_values = ['n/a', 'na', '--', '-', 'none', 'null', '', 'nan']\n",
        "df.replace(placeholder_values, np.nan, inplace=True)\n",
        "null_report = df.isnull().sum()\n",
        "null_report = null_report[null_report > 0]\n",
        "if not null_report.empty:\n",
        "    log(f\"Missing values found in columns:\\n{null_report}\")\n",
        "\n",
        "# 5. flag constant columns\n",
        "constant_cols = [col for col in df.columns if df[col].nunique() == 1]\n",
        "if constant_cols:\n",
        "    log(f\"Constant columns (consider removing): {constant_cols}\")\n",
        "\n",
        "# 6. flag high cardinality categorical columns\n",
        "high_card_cols = [col for col in df.select_dtypes(include='object') if df[col].nunique() > 100]\n",
        "if high_card_cols:\n",
        "    log(f\"High-cardinality columns (consider encoding strategies): {high_card_cols}\")\n",
        "\n",
        "# 7. detect numeric outliers using IQR\n",
        "num_cols = df.select_dtypes(include=np.number).columns\n",
        "outlier_report = {}\n",
        "for col in num_cols:\n",
        "    q1, q3 = df[col].quantile([0.25, 0.75])\n",
        "    iqr = q3 - q1\n",
        "    lower = q1 - 1.5 * iqr\n",
        "    upper = q3 + 1.5 * iqr\n",
        "    outliers = df[(df[col] < lower) | (df[col] > upper)][col].count()\n",
        "    if outliers > 0:\n",
        "        outlier_report[col] = outliers\n",
        "if outlier_report:\n",
        "    log(f\"Potential numeric outliers detected:\\n{outlier_report}\")\n",
        "\n",
        "# 8. convert applicable columns to category\n",
        "for col in df.select_dtypes(include='object'):\n",
        "    n_unique = df[col].nunique()\n",
        "    if n_unique < len(df) * 0.05:\n",
        "        df[col] = df[col].astype('category')\n",
        "log(\"Converted suitable object columns to category dtype.\")\n",
        "\n",
        "log(\"Data cleaning complete.\")\n",
        "\n",
        "clean_df = df\n",
        "print(clean_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRb_3YYff99v",
        "outputId": "3e394c55-601f-41a2-bac4-eb2391818fe6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Standardized column names.\n",
            "[INFO] Standardized string columns (lowercase + trimmed).\n",
            "[INFO] High-cardinality columns (consider encoding strategies): ['borrower_id', 'loan_id']\n",
            "[INFO] Potential numeric outliers detected:\n",
            "{'outstanding_loan_amount': np.int64(3), 'monthly_emi': np.int64(35), 'num_missed_payments': np.int64(21), 'collection_attempts': np.int64(40)}\n",
            "[INFO] Converted suitable object columns to category dtype.\n",
            "[INFO] Data cleaning complete.\n",
            "  borrower_id  age  gender employment_type  monthly_income  num_dependents  \\\n",
            "0       brw_1   59    male        salaried          215422               0   \n",
            "1       brw_2   49  female        salaried           60893               0   \n",
            "2       brw_3   35    male        salaried          116520               1   \n",
            "3       brw_4   63  female        salaried          140818               2   \n",
            "4       brw_5   28    male        salaried           76272               1   \n",
            "\n",
            "  loan_id  loan_amount  loan_tenure  interest_rate  ... collateral_value  \\\n",
            "0    ln_1      1445796           60          12.39  ...     1.727997e+06   \n",
            "1    ln_2      1044620           12          13.47  ...     1.180032e+06   \n",
            "2    ln_3      1923410           72           7.74  ...     2.622540e+06   \n",
            "3    ln_4      1811663           36          12.23  ...     1.145493e+06   \n",
            "4    ln_5        88578           48          16.13  ...     0.000000e+00   \n",
            "\n",
            "   outstanding_loan_amount  monthly_emi  payment_history num_missed_payments  \\\n",
            "0             2.914130e+05      4856.88          on-time                   0   \n",
            "1             6.652042e+05     55433.68          on-time                   0   \n",
            "2             1.031372e+06     14324.61          delayed                   2   \n",
            "3             2.249739e+05      6249.28          on-time                   1   \n",
            "4             3.918989e+04       816.46          on-time                   1   \n",
            "\n",
            "   days_past_due      recovery_status collection_attempts  collection_method  \\\n",
            "0              0  partially recovered                   1   settlement offer   \n",
            "1              0      fully recovered                   2   settlement offer   \n",
            "2            124      fully recovered                   2       legal notice   \n",
            "3             56      fully recovered                   2              calls   \n",
            "4             69      fully recovered                   0    debt collectors   \n",
            "\n",
            "  legal_action_taken  \n",
            "0                 no  \n",
            "1                 no  \n",
            "2                 no  \n",
            "3                 no  \n",
            "4                 no  \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        }
      ]
    }
  ]
}